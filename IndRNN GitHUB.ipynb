{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOCK MARKET -IndRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "The problem we are going to look at in this post is the stock market prices prediction problem.\n",
    "\n",
    "This is a problem where, given a day, month, and a year, the task is to predict the price of next days stocks . The data ranges from 1996 to 2010,  with 4836 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Name of the Dataset **  “TATAMOTORS.xlsx'“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from ind_rnn import IndRNNCell, RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-03-06</td>\n",
       "      <td>93.709801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996-03-07</td>\n",
       "      <td>94.188904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996-03-08</td>\n",
       "      <td>95.626099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996-03-09</td>\n",
       "      <td>96.967598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-03-10</td>\n",
       "      <td>100.033997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Close\n",
       "0 1996-03-06   93.709801\n",
       "1 1996-03-07   94.188904\n",
       "2 1996-03-08   95.626099\n",
       "3 1996-03-09   96.967598\n",
       "4 1996-03-10  100.033997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pandas.read_excel('TATAMOTORS.BO.xlsx', usecols=[0,4], skipfooter=3)\n",
    "dataset.fillna(method='ffill', inplace=True)\n",
    "\n",
    "plt.plot(dataset['Close'])\n",
    "plt.show()\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset sales-of-soaps.csv\n",
    "dataframe = pandas.read_excel('TATAMOTORS.BO.xlsx', usecols=[4])\n",
    "#dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1], engine='python')\n",
    "dataframe.fillna(method='ffill', inplace=True)\n",
    "\n",
    "dataframe.head()\n",
    "#print(type(dataframe.dtypes))\n",
    "\n",
    "dataset = dataframe.values      ##   convert the data-frame to its Numpy-array\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))\n",
    "\n",
    "forward_days = 10\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=40):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-forward_days+1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "\n",
    "# reshape into X=t and Y=t+1\n",
    "\n",
    "#40 is the number of days to consider in prediction\n",
    "look_back = 40\n",
    "\n",
    "\"\"\"\n",
    "Doing a Train-Test Split\n",
    "Train: 67%\n",
    "Test: 33%\n",
    "\"\"\"\n",
    "\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "trainX.shape\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "num_classes = 10\n",
    "epochs = 10     # 200  \n",
    "hidden_units = 64  # 128\n",
    "\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "\n",
    "# cells = [IndRNNCell(hidden_units), IndRNNCell(hidden_units)]\n",
    "cells = [IndRNNCell(4), IndRNNCell(4)]\n",
    "\n",
    "from ind_rnn import IndRNNCell, RNN\n",
    "from ind_rnn import IndRNN\n",
    "#model = load_model('my_model.h5',  custom_objects={'IndRNNCell': IndRNNCell, 'IndRNN': IndRNN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate IRNN...\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\Downloads\\TimeSeries-1-master\\TimeSeries-1-master\\ind_rnn.py:143: UserWarning: IndRNNCell: Number of timesteps could not be determined. \n",
      "Defaulting to max clipping range of 1.0. \n",
      "If this model was trained using a specific timestep during training, inference may be wrong due to this default setting.\n",
      "Please ensure that you use the same number of timesteps during training and evaluation\n",
      "  warnings.warn(\"IndRNNCell: Number of timesteps could not be determined. \\n\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Evaluate IRNN...')\n",
    "from ind_rnn import IndRNNCell, RNN\n",
    "from ind_rnn import IndRNN\n",
    "\n",
    "# create the IndRNN network\n",
    "model = Sequential()\n",
    "model.add(RNN(cells, input_shape=(look_back, 1), return_sequences=True))\n",
    "model.add(IndRNN(32, recurrent_clip_min=-1, recurrent_clip_max=-1, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "model.add(RNN(cells, return_sequences=True))\n",
    "model.add(IndRNN(32, recurrent_clip_min=-1, recurrent_clip_max=-1, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "model.add(RNN(cells, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "\n",
    "from keras import optimizers\n",
    "#optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer= 'adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "'''\n",
    "Return sequences\n",
    "Return sequences refer to return the hidden state a<t>. By default, the return_sequences is set to False in Keras RNN layers, and this means the RNN layer will only return the last hidden state output a<T>. The last hidden state output captures an abstract representation of the input sequence. In some case, it is all we need, such as a classification or regression model where the RNN is followed by the Dense layer(s) to generate logits for news topic classification or score for sentiment analysis, or in a generative model to produce the softmax probabilities for the next possible char.\n",
    "\n",
    "In other cases, we need the full sequence as the output. Setting return_sequences to True is necessary.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_1 (RNN)                  (None, 40, 4)             356       \n",
      "_________________________________________________________________\n",
      "ind_rnn_1 (IndRNN)           (None, 40, 32)            192       \n",
      "_________________________________________________________________\n",
      "rnn_2 (RNN)                  (None, 40, 4)             356       \n",
      "_________________________________________________________________\n",
      "ind_rnn_2 (IndRNN)           (None, 40, 32)            192       \n",
      "_________________________________________________________________\n",
      "rnn_3 (RNN)                  (None, 4)                 356       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 745\n",
      "Trainable params: 745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install GraphViz \n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/ProgramData/Anaconda3/Library/bin/graphviz/'\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      " - 4s - loss: 2.1404e-05 - acc: 3.1338e-04\n",
      "Epoch 2/60\n",
      " - 2s - loss: 1.4416e-05 - acc: 3.1338e-04\n",
      "Epoch 3/60\n",
      " - 2s - loss: 1.6087e-05 - acc: 3.1338e-04\n",
      "Epoch 4/60\n",
      " - 3s - loss: 1.4451e-05 - acc: 3.1338e-04\n",
      "Epoch 5/60\n",
      " - 2s - loss: 1.3802e-05 - acc: 3.1338e-04\n",
      "Epoch 6/60\n",
      " - 2s - loss: 1.6244e-05 - acc: 3.1338e-04\n",
      "Epoch 7/60\n",
      " - 2s - loss: 1.4505e-05 - acc: 3.1338e-04\n",
      "Epoch 8/60\n",
      " - 2s - loss: 1.4319e-05 - acc: 3.1338e-04\n",
      "Epoch 9/60\n",
      " - 2s - loss: 1.4321e-05 - acc: 3.1338e-04\n",
      "Epoch 10/60\n",
      " - 2s - loss: 1.4925e-05 - acc: 3.1338e-04\n",
      "Epoch 11/60\n",
      " - 2s - loss: 1.6470e-05 - acc: 3.1338e-04\n",
      "Epoch 12/60\n",
      " - 2s - loss: 1.4164e-05 - acc: 3.1338e-04\n",
      "Epoch 13/60\n",
      " - 2s - loss: 1.4424e-05 - acc: 3.1338e-04\n",
      "Epoch 14/60\n",
      " - 2s - loss: 1.5358e-05 - acc: 3.1338e-04\n",
      "Epoch 15/60\n",
      " - 2s - loss: 1.5190e-05 - acc: 3.1338e-04\n",
      "Epoch 16/60\n",
      " - 2s - loss: 1.4250e-05 - acc: 3.1338e-04\n",
      "Epoch 17/60\n",
      " - 2s - loss: 1.4947e-05 - acc: 3.1338e-04\n",
      "Epoch 18/60\n",
      " - 2s - loss: 1.4460e-05 - acc: 3.1338e-04\n",
      "Epoch 19/60\n",
      " - 3s - loss: 1.5391e-05 - acc: 3.1338e-04\n",
      "Epoch 20/60\n",
      " - 2s - loss: 1.3836e-05 - acc: 3.1338e-04\n",
      "Epoch 21/60\n",
      " - 2s - loss: 1.6033e-05 - acc: 3.1338e-04\n",
      "Epoch 22/60\n",
      " - 2s - loss: 1.5885e-05 - acc: 3.1338e-04\n",
      "Epoch 23/60\n",
      " - 2s - loss: 1.5385e-05 - acc: 3.1338e-04\n",
      "Epoch 24/60\n",
      " - 2s - loss: 1.4131e-05 - acc: 3.1338e-04\n",
      "Epoch 25/60\n",
      " - 2s - loss: 1.6239e-05 - acc: 3.1338e-04\n",
      "Epoch 26/60\n",
      " - 2s - loss: 1.5939e-05 - acc: 3.1338e-04\n",
      "Epoch 27/60\n",
      " - 2s - loss: 1.6253e-05 - acc: 3.1338e-04\n",
      "Epoch 28/60\n",
      " - 2s - loss: 1.4198e-05 - acc: 3.1338e-04\n",
      "Epoch 29/60\n",
      " - 2s - loss: 1.4282e-05 - acc: 3.1338e-04\n",
      "Epoch 30/60\n",
      " - 2s - loss: 1.6615e-05 - acc: 3.1338e-04\n",
      "Epoch 31/60\n",
      " - 2s - loss: 1.4574e-05 - acc: 3.1338e-04\n",
      "Epoch 32/60\n",
      " - 2s - loss: 1.5269e-05 - acc: 3.1338e-04\n",
      "Epoch 33/60\n",
      " - 2s - loss: 1.4468e-05 - acc: 3.1338e-04\n",
      "Epoch 34/60\n",
      " - 2s - loss: 1.4459e-05 - acc: 3.1338e-04\n",
      "Epoch 35/60\n",
      " - 2s - loss: 1.6243e-05 - acc: 3.1338e-04\n",
      "Epoch 36/60\n",
      " - 2s - loss: 1.4601e-05 - acc: 3.1338e-04\n",
      "Epoch 37/60\n",
      " - 2s - loss: 1.5360e-05 - acc: 3.1338e-04\n",
      "Epoch 38/60\n",
      " - 2s - loss: 1.6882e-05 - acc: 3.1338e-04\n",
      "Epoch 39/60\n",
      " - 2s - loss: 1.4441e-05 - acc: 3.1338e-04\n",
      "Epoch 40/60\n",
      " - 2s - loss: 1.5268e-05 - acc: 3.1338e-04\n",
      "Epoch 41/60\n",
      " - 2s - loss: 1.4976e-05 - acc: 3.1338e-04\n",
      "Epoch 42/60\n",
      " - 2s - loss: 1.5846e-05 - acc: 3.1338e-04\n",
      "Epoch 43/60\n",
      " - 2s - loss: 1.4289e-05 - acc: 3.1338e-04\n",
      "Epoch 44/60\n",
      " - 2s - loss: 1.5062e-05 - acc: 3.1338e-04\n",
      "Epoch 45/60\n",
      " - 2s - loss: 1.3310e-05 - acc: 3.1338e-04\n",
      "Epoch 46/60\n",
      " - 2s - loss: 1.4713e-05 - acc: 3.1338e-04\n",
      "Epoch 47/60\n",
      " - 2s - loss: 1.4318e-05 - acc: 3.1338e-04\n",
      "Epoch 48/60\n",
      " - 2s - loss: 1.4852e-05 - acc: 3.1338e-04\n",
      "Epoch 49/60\n",
      " - 2s - loss: 1.4084e-05 - acc: 3.1338e-04\n",
      "Epoch 50/60\n",
      " - 2s - loss: 1.4527e-05 - acc: 3.1338e-04\n",
      "Epoch 51/60\n",
      " - 2s - loss: 1.5112e-05 - acc: 3.1338e-04\n",
      "Epoch 52/60\n",
      " - 2s - loss: 2.0263e-05 - acc: 3.1338e-04\n",
      "Epoch 53/60\n",
      " - 2s - loss: 1.4241e-05 - acc: 3.1338e-04\n",
      "Epoch 54/60\n",
      " - 2s - loss: 1.4229e-05 - acc: 3.1338e-04\n",
      "Epoch 55/60\n",
      " - 2s - loss: 1.6168e-05 - acc: 3.1338e-04\n",
      "Epoch 56/60\n",
      " - 2s - loss: 1.3981e-05 - acc: 3.1338e-04\n",
      "Epoch 57/60\n",
      " - 2s - loss: 1.3283e-05 - acc: 3.1338e-04\n",
      "Epoch 58/60\n",
      " - 2s - loss: 1.6660e-05 - acc: 3.1338e-04\n",
      "Epoch 59/60\n",
      " - 2s - loss: 1.5878e-05 - acc: 3.1338e-04\n",
      "Epoch 60/60\n",
      " - 2s - loss: 1.3896e-05 - acc: 3.1338e-04\n",
      "Wall time: 2min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218db565b38>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the LSTM network\n",
    "model.fit(trainX, trainY, epochs=200, batch_size=40, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is fit, we can estimate the performance of the model on the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4cf955b397a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(trainX, trainY, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-df125b6235fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "print(scores)\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note that we invert the predictions before calculating error scores \n",
    "to ensure that performance is reported in the same units as the original data (stock prices).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 6.69 MSE\n",
      "Test Score: 46.25 MSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = mean_squared_error(trainY[0], trainPredict[:,0])\n",
    "print('Train Score: %.2f MSE' % (trainScore))\n",
    "testScore = mean_squared_error(testY[0], testPredict[:,0])\n",
    "print('Test Score: %.2f MSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM   - Train Score: 23.70 RMSE Test Score: 58.87 RMSE (LSTM - 4)\n",
    "## IndRNN - Train Score: 24.05 RMSE Test Score: 52.45 RMSE [Cell = 4,4]\n",
    "## IndRNN - Train Score: 23.99 RMSE Test Score: 51.99 RMSE [Cell = 3,3]\n",
    "## IndRnn - Train Score: 23.25 RMSE Test Score: 49.35 RMSE [Cell = 3,3] Look-back=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0    46.245119\n",
      "dtype: float64\n",
      "Mean Absolute Error  0    4.923615\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of how the dataset was prepared, we must shift the predictions so that they align on the x-axis with the original dataset. Once prepared, the data is plotted, showing the original dataset in blue, the predictions for the training dataset in green, and the predictions on the unseen test dataset in black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1547,1) into shape (1563,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-00ed45dc004a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtestPredictPlot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtestPredictPlot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtestPredictPlot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainPredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestPredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (1547,1) into shape (1563,1)"
     ]
    }
   ],
   "source": [
    "datedate = pandas.read_excel('TATAMOTORS.BO.xlsx', usecols=[0], skipfooter=3)\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.grid()\n",
    "plt.plot(datedate.tail(1547),testPredict, label='Predicted Value', color='red')\n",
    "plt.plot(datedate.tail(1547),testY[0], label='Real Value', color='blue')\n",
    "plt.xlabel('Date', fontsize=25)\n",
    "plt.ylabel('Price in USD', fontsize=25)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
